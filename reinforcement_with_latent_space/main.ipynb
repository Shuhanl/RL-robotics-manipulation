{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VEcuSBdHQpfd",
        "outputId": "2a641c10-8d86-468b-c052-441c1ca9fe35"
      },
      "outputs": [],
      "source": [
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HtuK2i1jQ4nc",
        "outputId": "8cace65a-159f-4e35-d62a-1481f08d0007"
      },
      "outputs": [],
      "source": [
        "from collections import OrderedDict\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "import torch\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "# from google.colab import drive\n",
        "\n",
        "# import imageio\n",
        "# from base64 import b64encode\n",
        "# from IPython.display import HTML\n",
        "import parameters as params\n",
        "from utils import save_checkpoint, load_checkpoint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from simulator import RobotSimulator\n",
        "\n",
        "urdf_path = 'A02L-M1.urdf'  # Change this to your URDF file path\n",
        "simulator = RobotSimulator(gui=True)\n",
        "simulator.connect()\n",
        "simulator.load_robot(urdf_path)\n",
        "simulator.set_gravity()\n",
        "simulator.simulate()\n",
        "simulator.disconnect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xjX3oBFf5YpY",
        "outputId": "18f2eb25-47b9-4ff2-c1cf-b39f6bd5b2e5"
      },
      "outputs": [],
      "source": [
        "# from train import AgentTrainer\n",
        "# from utils import image_process\n",
        "# from env import Stack\n",
        "\n",
        "# class SerialModelTrain():\n",
        "#   def __init__(self):\n",
        "#     self.num_episode = 10\n",
        "#     self.initial_memory_size = 5\n",
        "#     self.episode_rewards = []\n",
        "#     self.num_average_epidodes = 100\n",
        "#     self.save_every = 100\n",
        "\n",
        "#     self.max_steps = 100\n",
        "#     self.envs = Stack('Panda')\n",
        "#     self.agent_trainer = AgentTrainer()\n",
        "\n",
        "#     self.evaluate_interval = 10\n",
        "#     self.reward_window = 20\n",
        "#     self.reward_values = [0]*self.reward_window \n",
        "#     self.averge_reward = 0 \n",
        "\n",
        "#   def init_buffer(self):\n",
        "#     \"\"\" Initially, put the data into the replay buffer when an action with noise was taken \"\"\"\n",
        "#     state = OrderedDict()\n",
        "#     next_state = OrderedDict()\n",
        "#     done = False\n",
        "#     reward = 0 \n",
        "\n",
        "#     state = self.env.reset()\n",
        "\n",
        "#     for step in range(self.initial_memory_size):\n",
        "#         if step % self.max_steps == 0:\n",
        "#           state = self.env.reset()\n",
        "\n",
        "#         action = np.random.randn(params.action_dim) # sample random action\n",
        "#         next_state, reward, done, info = self.env.step(action)\n",
        "\n",
        "#         # verify the following in the server\n",
        "#         vision = image_process(state['frontview_image'])\n",
        "#         vision_next = image_process(next_state['frontview_image'])\n",
        "#         action = torch.tensor(action, dtype=torch.float32)\n",
        "#         action = action.squeeze(0)\n",
        "\n",
        "#         self.agent_trainer.pri_buffer.store(state, action, reward, next_state, done)\n",
        "#         state = next_state\n",
        "\n",
        "#     print('%d Data collected' % self.initial_memory_size)\n",
        "\n",
        "\n",
        "#   def train_model(self):\n",
        "#     state = OrderedDict() \n",
        "#     next_state = OrderedDict() \n",
        "#     done = False \n",
        "#     reward = 0 \n",
        "\n",
        "#     for episode in range(self.num_episode):\n",
        "#       state = self.env.reset()\n",
        "#       episode_reward = 0\n",
        "#       for t in range(self.max_steps):\n",
        "#         vision = image_process(state['frontview_image'])\n",
        "\n",
        "#         robot_state = [\n",
        "#             np.array(state['robot0_eef_pos'], dtype=np.float32).flatten(),\n",
        "#             np.array(state['robot0_eef_quat'], dtype=np.float32).flatten()\n",
        "#         ]\n",
        "\n",
        "#         robot_state = np.concatenate(robot_state)\n",
        "#         robot_state = torch.tensor(robot_state, dtype=torch.float32)\n",
        "\n",
        "#         action = self.agent_trainer.get_action(vision, robot_state)\n",
        "#         next_state, reward, done, info = self.env.step(action[0])\n",
        "\n",
        "#         if len(self.reward_value)>=20:\n",
        "#           self.reward_value.pop(0)\n",
        "#           self.reward_value.append(reward)\n",
        "\n",
        "#         # verify the following in the server\n",
        "#         vision_next = image_process(next_state['frontview_image'])\n",
        "#         vision = vision.squeeze(0)\n",
        "#         vision_next = vision_next.squeeze(0)\n",
        "#         action = torch.tensor(action, dtype=torch.float32)\n",
        "#         action = action.squeeze(0)\n",
        "\n",
        "#         self.agent_trainer.pri_buffer.store(state, action, reward, next_state, done)\n",
        "#         state = next_state\n",
        "#         if any(done):\n",
        "#           break\n",
        "\n",
        "#       episode_reward += reward\n",
        "\n",
        "#       if episode % 5 == 0:\n",
        "#         self.agent_trainer.update()\n",
        "#       self.episode_rewards.append(episode_reward)\n",
        "#       if episode % self.evaluate_interval == 0:\n",
        "#         self.averge_reward = np.mean(self.reward_value)\n",
        "#         print(self.averge_reward)\n",
        "#       if episode % 100 == 0:\n",
        "#         print(\"Episode %d finished | Episode reward %f\" % (episode, episode_reward))\n",
        "#       if episode % self.save_every == 0:\n",
        "#         self.agent_trainer.save_checkpoint(episode)\n",
        "\n",
        "#     self.env.close()\n",
        "\n",
        "#   def plot(self):\n",
        "#     # Compute the moving average of cumulative rewards\n",
        "#     moving_average = np.convolve(self.episode_rewards, np.ones(self.num_average_epidodes)/self.num_average_epidodes, mode='valid')\n",
        "#     plt.plot(np.arange(len(moving_average)),moving_average)\n",
        "#     plt.title('Average rewards in %d episodes' % self.num_average_epidodes)\n",
        "#     plt.xlabel('episode')\n",
        "#     plt.ylabel('rewards')\n",
        "#     plt.show()\n",
        "\n",
        "#   def test_model(self):\n",
        "#     env = Stack('Panda')\n",
        "#     states = env.reset()\n",
        "#     self.agent_trainer.load_checkpoint('/content/drive/My Drive/check_point')\n",
        "\n",
        "#     frames = []\n",
        "#     for i in range(100):\n",
        "#       frames.append(states['frontview_image'])  # Append the image to the frames list\n",
        "#       obs = image_process(states['frontview_image'])\n",
        "#       action = self.agent_trainer.get_action(obs)\n",
        "\n",
        "#       next_state, reward, done, info = env.step(action[0])\n",
        "#       state = next_state\n",
        "\n",
        "\n",
        "#     imageio.mimwrite('robosuite_video.mp4', frames, fps=20)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OvtZ6Z_taf3M"
      },
      "source": [
        "## Train agent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ilSkkI7apWmY",
        "outputId": "819fb03b-7aa6-4f58-b5ab-00e134b3d0be"
      },
      "outputs": [],
      "source": [
        "# # drive.mount('/content/drive')\n",
        "\n",
        "# serial_train = SerialModelTrain()\n",
        "# serial_train.init_buffer()\n",
        "# serial_train.train_model()\n",
        "# serial_train.plot()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2rgxoeCJaoK8"
      },
      "source": [
        "## Test Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NRpDqBbitbMT"
      },
      "outputs": [],
      "source": [
        "# serial_train.test_model()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cYRnB8zG3QPL"
      },
      "outputs": [],
      "source": [
        "# \"\"\" Load video and encode it in base64 format \"\"\"\n",
        "# video_path = 'robosuite_video.mp4'\n",
        "# video_data = open(video_path, 'rb').read()\n",
        "# video_encoded = b64encode(video_data).decode()\n",
        "\n",
        "# # Display video using HTML\n",
        "# HTML(f\"\"\"\n",
        "# <video width=\"640\" height=\"480\" controls>\n",
        "#   <source src=\"data:video/mp4;base64,{video_encoded}\" type=\"video/mp4\">\n",
        "# </video>\n",
        "# \"\"\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
