{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VEcuSBdHQpfd",
        "outputId": "7af690f9-d806-4b4b-c37f-cd7f69e1b5fd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting robosuite\n",
            "  Downloading robosuite-1.4.0-py3-none-any.whl (193.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.5/193.5 MB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.10/dist-packages (from robosuite) (1.23.5)\n",
            "Requirement already satisfied: numba>=0.49.1 in /usr/local/lib/python3.10/dist-packages (from robosuite) (0.56.4)\n",
            "Requirement already satisfied: scipy>=1.2.3 in /usr/local/lib/python3.10/dist-packages (from robosuite) (1.11.3)\n",
            "Collecting mujoco>=2.3.0 (from robosuite)\n",
            "  Downloading mujoco-2.3.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.6/4.6 MB\u001b[0m \u001b[31m79.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from robosuite) (9.4.0)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (from robosuite) (4.8.0.76)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from mujoco>=2.3.0->robosuite) (1.4.0)\n",
            "Collecting glfw (from mujoco>=2.3.0->robosuite)\n",
            "  Downloading glfw-2.6.2-py2.py27.py3.py30.py31.py32.py33.py34.py35.py36.py37.py38-none-manylinux2014_x86_64.whl (208 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m208.2/208.2 kB\u001b[0m \u001b[31m17.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyopengl in /usr/local/lib/python3.10/dist-packages (from mujoco>=2.3.0->robosuite) (3.1.7)\n",
            "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.49.1->robosuite) (0.39.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from numba>=0.49.1->robosuite) (67.7.2)\n",
            "Installing collected packages: glfw, mujoco, robosuite\n",
            "Successfully installed glfw-2.6.2 mujoco-2.3.7 robosuite-1.4.0\n",
            "Collecting tianshou\n",
            "  Downloading tianshou-0.5.1-py3-none-any.whl (163 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m163.1/163.1 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting gymnasium>=0.26.0 (from tianshou)\n",
            "  Downloading gymnasium-0.29.1-py3-none-any.whl (953 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m953.9/953.9 kB\u001b[0m \u001b[31m26.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from tianshou) (4.66.1)\n",
            "Requirement already satisfied: numpy>1.16.0 in /usr/local/lib/python3.10/dist-packages (from tianshou) (1.23.5)\n",
            "Requirement already satisfied: tensorboard>=2.5.0 in /usr/local/lib/python3.10/dist-packages (from tianshou) (2.13.0)\n",
            "Requirement already satisfied: torch>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from tianshou) (2.0.1+cu118)\n",
            "Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.10/dist-packages (from tianshou) (0.56.4)\n",
            "Requirement already satisfied: h5py>=2.10.0 in /usr/local/lib/python3.10/dist-packages (from tianshou) (3.9.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tianshou) (23.2)\n",
            "Collecting pettingzoo>=1.22 (from tianshou)\n",
            "  Downloading pettingzoo-1.24.1-py3-none-any.whl (840 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m840.8/840.8 kB\u001b[0m \u001b[31m60.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium>=0.26.0->tianshou) (2.2.1)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium>=0.26.0->tianshou) (4.5.0)\n",
            "Collecting farama-notifications>=0.0.1 (from gymnasium>=0.26.0->tianshou)\n",
            "  Downloading Farama_Notifications-0.0.4-py3-none-any.whl (2.5 kB)\n",
            "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.51.0->tianshou) (0.39.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from numba>=0.51.0->tianshou) (67.7.2)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.5.0->tianshou) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.5.0->tianshou) (1.59.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.5.0->tianshou) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.5.0->tianshou) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.5.0->tianshou) (3.5)\n",
            "Requirement already satisfied: protobuf>=3.19.6 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.5.0->tianshou) (3.20.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.5.0->tianshou) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.5.0->tianshou) (0.7.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.5.0->tianshou) (3.0.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.5.0->tianshou) (0.41.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->tianshou) (3.12.4)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->tianshou) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->tianshou) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->tianshou) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->tianshou) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.4.0->tianshou) (3.27.6)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.4.0->tianshou) (17.0.2)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.5.0->tianshou) (5.3.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.5.0->tianshou) (0.3.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.5.0->tianshou) (1.16.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.5.0->tianshou) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard>=2.5.0->tianshou) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard>=2.5.0->tianshou) (3.3.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard>=2.5.0->tianshou) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard>=2.5.0->tianshou) (2.0.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard>=2.5.0->tianshou) (2023.7.22)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard>=2.5.0->tianshou) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.4.0->tianshou) (1.3.0)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.5.0->tianshou) (0.5.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard>=2.5.0->tianshou) (3.2.2)\n",
            "Installing collected packages: farama-notifications, gymnasium, pettingzoo, tianshou\n",
            "Successfully installed farama-notifications-0.0.4 gymnasium-0.29.1 pettingzoo-1.24.1 tianshou-0.5.1\n"
          ]
        }
      ],
      "source": [
        "!pip install robosuite\n",
        "!pip install tianshou"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HtuK2i1jQ4nc",
        "outputId": "a616cdff-f50a-4e5e-87f8-a7af23d1f1f5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[robosuite WARNING] No private macro file found! (__init__.py:7)\n",
            "WARNING:robosuite_logs:No private macro file found!\n",
            "[robosuite WARNING] It is recommended to use a private macro file (__init__.py:8)\n",
            "WARNING:robosuite_logs:It is recommended to use a private macro file\n",
            "[robosuite WARNING] To setup, run: python /usr/local/lib/python3.10/dist-packages/robosuite/scripts/setup_macros.py (__init__.py:9)\n",
            "WARNING:robosuite_logs:To setup, run: python /usr/local/lib/python3.10/dist-packages/robosuite/scripts/setup_macros.py\n"
          ]
        }
      ],
      "source": [
        "from collections import OrderedDict\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.nn.utils import clip_grad_norm_\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from typing import Any, List, Optional, Tuple, Union\n",
        "import copy\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from robosuite.environments.manipulation.single_arm_env import SingleArmEnv\n",
        "from robosuite.models.arenas import TableArena\n",
        "from robosuite.models.objects import BoxObject\n",
        "from robosuite.models.tasks import ManipulationTask\n",
        "from robosuite.utils.mjcf_utils import CustomMaterial\n",
        "from robosuite.utils.observables import Observable, sensor\n",
        "from robosuite.utils.placement_samplers import UniformRandomSampler\n",
        "from robosuite.utils.transform_utils import convert_quat\n",
        "\n",
        "from tianshou.data import Batch, ReplayBuffer, SegmentTree, to_numpy\n",
        "\n",
        "import imageio\n",
        "from base64 import b64encode\n",
        "from IPython.display import HTML"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q0k0slELSoVj",
        "outputId": "7f77d9be-f81d-463d-d518-e9482ea9a174"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ],
      "source": [
        "class Stack(SingleArmEnv):\n",
        "    \"\"\"\n",
        "    This class corresponds to the stacking task for a single robot arm.\n",
        "\n",
        "    Args:\n",
        "        robots (str or list of str): Specification for specific robot arm(s) to be instantiated within this env\n",
        "            (e.g: \"Sawyer\" would generate one arm; [\"Panda\", \"Panda\", \"Sawyer\"] would generate three robot arms)\n",
        "            Note: Must be a single single-arm robot!\n",
        "\n",
        "        env_configuration (str): Specifies how to position the robots within the environment (default is \"default\").\n",
        "            For most single arm environments, this argument has no impact on the robot setup.\n",
        "\n",
        "        controller_configs (str or list of dict): If set, contains relevant controller parameters for creating a\n",
        "            custom controller. Else, uses the default controller for this specific task. Should either be single\n",
        "            dict if same controller is to be used for all robots or else it should be a list of the same length as\n",
        "            \"robots\" param\n",
        "\n",
        "        gripper_types (str or list of str): type of gripper, used to instantiate\n",
        "            gripper models from gripper factory. Default is \"default\", which is the default grippers(s) associated\n",
        "            with the robot(s) the 'robots' specification. None removes the gripper, and any other (valid) model\n",
        "            overrides the default gripper. Should either be single str if same gripper type is to be used for all\n",
        "            robots or else it should be a list of the same length as \"robots\" param\n",
        "\n",
        "        initialization_noise (dict or list of dict): Dict containing the initialization noise parameters.\n",
        "            The expected keys and corresponding value types are specified below:\n",
        "\n",
        "            :`'magnitude'`: The scale factor of uni-variate random noise applied to each of a robot's given initial\n",
        "                joint positions. Setting this value to `None` or 0.0 results in no noise being applied.\n",
        "                If \"gaussian\" type of noise is applied then this magnitude scales the standard deviation applied,\n",
        "                If \"uniform\" type of noise is applied then this magnitude sets the bounds of the sampling range\n",
        "            :`'type'`: Type of noise to apply. Can either specify \"gaussian\" or \"uniform\"\n",
        "\n",
        "            Should either be single dict if same noise value is to be used for all robots or else it should be a\n",
        "            list of the same length as \"robots\" param\n",
        "\n",
        "            :Note: Specifying \"default\" will automatically use the default noise settings.\n",
        "                Specifying None will automatically create the required dict with \"magnitude\" set to 0.0.\n",
        "\n",
        "        table_full_size (3-tuple): x, y, and z dimensions of the table.\n",
        "\n",
        "        table_friction (3-tuple): the three mujoco friction parameters for\n",
        "            the table.\n",
        "\n",
        "        use_camera_obs (bool): if True, every observation includes rendered image(s)\n",
        "\n",
        "        use_object_obs (bool): if True, include object (cube) information in\n",
        "            the observation.\n",
        "\n",
        "        reward_scale (None or float): Scales the normalized reward function by the amount specified.\n",
        "            If None, environment reward remains unnormalized\n",
        "\n",
        "        reward_shaping (bool): if True, use dense rewards.\n",
        "\n",
        "        placement_initializer (ObjectPositionSampler): if provided, will\n",
        "            be used to place objects on every reset, else a UniformRandomSampler\n",
        "            is used by default.\n",
        "\n",
        "        has_renderer (bool): If true, render the simulation state in\n",
        "            a viewer instead of headless mode.\n",
        "\n",
        "        has_offscreen_renderer (bool): True if using off-screen rendering\n",
        "\n",
        "        render_camera (str): Name of camera to render if `has_renderer` is True. Setting this value to 'None'\n",
        "            will result in the default angle being applied, which is useful as it can be dragged / panned by\n",
        "            the user using the mouse\n",
        "\n",
        "        render_collision_mesh (bool): True if rendering collision meshes in camera. False otherwise.\n",
        "\n",
        "        render_visual_mesh (bool): True if rendering visual meshes in camera. False otherwise.\n",
        "\n",
        "        render_gpu_device_id (int): corresponds to the GPU device id to use for offscreen rendering.\n",
        "            Defaults to -1, in which case the device will be inferred from environment variables\n",
        "            (GPUS or CUDA_VISIBLE_DEVICES).\n",
        "\n",
        "        control_freq (float): how many control signals to receive in every second. This sets the amount of\n",
        "            simulation time that passes between every action input.\n",
        "\n",
        "        horizon (int): Every episode lasts for exactly @horizon timesteps.\n",
        "\n",
        "        ignore_done (bool): True if never terminating the environment (ignore @horizon).\n",
        "\n",
        "        hard_reset (bool): If True, re-loads model, sim, and render object upon a reset call, else,\n",
        "            only calls sim.reset and resets all robosuite-internal variables\n",
        "\n",
        "        camera_names (str or list of str): name of camera to be rendered. Should either be single str if\n",
        "            same name is to be used for all cameras' rendering or else it should be a list of cameras to render.\n",
        "\n",
        "            :Note: At least one camera must be specified if @use_camera_obs is True.\n",
        "\n",
        "            :Note: To render all robots' cameras of a certain type (e.g.: \"robotview\" or \"eye_in_hand\"), use the\n",
        "                convention \"all-{name}\" (e.g.: \"all-robotview\") to automatically render all camera images from each\n",
        "                robot's camera list).\n",
        "\n",
        "        camera_heights (int or list of int): height of camera frame. Should either be single int if\n",
        "            same height is to be used for all cameras' frames or else it should be a list of the same length as\n",
        "            \"camera names\" param.\n",
        "\n",
        "        camera_widths (int or list of int): width of camera frame. Should either be single int if\n",
        "            same width is to be used for all cameras' frames or else it should be a list of the same length as\n",
        "            \"camera names\" param.\n",
        "\n",
        "        camera_depths (bool or list of bool): True if rendering RGB-D, and RGB otherwise. Should either be single\n",
        "            bool if same depth setting is to be used for all cameras or else it should be a list of the same length as\n",
        "            \"camera names\" param.\n",
        "\n",
        "        camera_segmentations (None or str or list of str or list of list of str): Camera segmentation(s) to use\n",
        "            for each camera. Valid options are:\n",
        "\n",
        "                `None`: no segmentation sensor used\n",
        "                `'instance'`: segmentation at the class-instance level\n",
        "                `'class'`: segmentation at the class level\n",
        "                `'element'`: segmentation at the per-geom level\n",
        "\n",
        "            If not None, multiple types of segmentations can be specified. A [list of str / str or None] specifies\n",
        "            [multiple / a single] segmentation(s) to use for all cameras. A list of list of str specifies per-camera\n",
        "            segmentation setting(s) to use.\n",
        "\n",
        "    Raises:\n",
        "        AssertionError: [Invalid number of robots specified]\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        robots,\n",
        "        env_configuration=\"default\",\n",
        "        controller_configs=None,\n",
        "        gripper_types=\"default\",\n",
        "        initialization_noise=\"default\",\n",
        "        table_full_size=(0.8, 0.8, 0.05),\n",
        "        table_friction=(1.0, 5e-3, 1e-4),\n",
        "        use_camera_obs=True,\n",
        "        use_object_obs=True,\n",
        "        reward_scale=1.0,\n",
        "        reward_shaping=True,\n",
        "        placement_initializer=None,\n",
        "        has_renderer=False,\n",
        "        has_offscreen_renderer=True,\n",
        "        render_camera=\"frontview\",\n",
        "        render_collision_mesh=False,\n",
        "        render_visual_mesh=True,\n",
        "        render_gpu_device_id=-1,\n",
        "        control_freq=20,\n",
        "        horizon=1000,\n",
        "        ignore_done=False,\n",
        "        hard_reset=True,\n",
        "        camera_names=\"frontview\",\n",
        "        camera_heights=256,\n",
        "        camera_widths=256,\n",
        "        camera_depths=False,\n",
        "        camera_segmentations=None,  # {None, instance, class, element}\n",
        "        renderer=\"mujoco\",\n",
        "        renderer_config=None,\n",
        "    ):\n",
        "        # settings for table top\n",
        "        self.table_full_size = table_full_size\n",
        "        self.table_friction = table_friction\n",
        "        self.table_offset = np.array((0, 0, 0.8))\n",
        "\n",
        "        # reward configuration\n",
        "        self.reward_scale = reward_scale\n",
        "        self.reward_shaping = reward_shaping\n",
        "\n",
        "        # whether to use ground-truth object states\n",
        "        self.use_object_obs = use_object_obs\n",
        "\n",
        "        # object placement initializer\n",
        "        self.placement_initializer = placement_initializer\n",
        "        self.deterministic_reset = True\n",
        "        self.obj_pos = np.array([0,0,0])\n",
        "        self.obj_quat = np.array([0, 0, 0])\n",
        "        self.joint_pos = np.array([0.0, 0.5, 0.0, -1.3, 0.0, 1.0, 0.785])\n",
        "\n",
        "        super().__init__(\n",
        "            robots=robots,\n",
        "            env_configuration=env_configuration,\n",
        "            controller_configs=controller_configs,\n",
        "            mount_types=\"default\",\n",
        "            gripper_types=gripper_types,\n",
        "            initialization_noise=initialization_noise,\n",
        "            use_camera_obs=use_camera_obs,\n",
        "            has_renderer=has_renderer,\n",
        "            has_offscreen_renderer=has_offscreen_renderer,\n",
        "            render_camera=render_camera,\n",
        "            render_collision_mesh=render_collision_mesh,\n",
        "            render_visual_mesh=render_visual_mesh,\n",
        "            render_gpu_device_id=render_gpu_device_id,\n",
        "            control_freq=control_freq,\n",
        "            horizon=horizon,\n",
        "            ignore_done=ignore_done,\n",
        "            hard_reset=hard_reset,\n",
        "            camera_names=camera_names,\n",
        "            camera_heights=camera_heights,\n",
        "            camera_widths=camera_widths,\n",
        "            camera_depths=camera_depths,\n",
        "            camera_segmentations=camera_segmentations,\n",
        "            renderer=renderer,\n",
        "            renderer_config=renderer_config,\n",
        "        )\n",
        "\n",
        "    def reward(self, action):\n",
        "        \"\"\"\n",
        "        Reward function for the task.\n",
        "\n",
        "        Sparse un-normalized reward:\n",
        "\n",
        "            - a discrete reward of 2.0 is provided if the red block is stacked on the green block\n",
        "\n",
        "        Un-normalized components if using reward shaping:\n",
        "\n",
        "            - Reaching: in [0, 0.25], to encourage the arm to reach the cube\n",
        "            - Grasping: in {0, 0.25}, non-zero if arm is grasping the cube\n",
        "            - Lifting: in {0, 1}, non-zero if arm has lifted the cube\n",
        "            - Aligning: in [0, 0.5], encourages aligning one cube over the other\n",
        "            - Stacking: in {0, 2}, non-zero if cube is stacked on other cube\n",
        "\n",
        "        The reward is max over the following:\n",
        "\n",
        "            - Reaching + Grasping\n",
        "            - Lifting + Aligning\n",
        "            - Stacking\n",
        "\n",
        "        The sparse reward only consists of the stacking component.\n",
        "\n",
        "        Note that the final reward is normalized and scaled by\n",
        "        reward_scale / 2.0 as well so that the max score is equal to reward_scale\n",
        "\n",
        "        Args:\n",
        "            action (np array): [NOT USED]\n",
        "\n",
        "        Returns:\n",
        "            float: reward value\n",
        "        \"\"\"\n",
        "        r_reach, r_lift, r_stack = self.staged_rewards()\n",
        "        if self.reward_shaping:\n",
        "            reward = max(r_reach, r_lift, r_stack)\n",
        "        else:\n",
        "            reward = 2.0 if r_stack > 0 else 0.0\n",
        "\n",
        "        if self.reward_scale is not None:\n",
        "            reward *= self.reward_scale / 2.0\n",
        "\n",
        "        return reward\n",
        "\n",
        "    def staged_rewards(self):\n",
        "        \"\"\"\n",
        "        Helper function to calculate staged rewards based on current physical states.\n",
        "\n",
        "        Returns:\n",
        "            3-tuple:\n",
        "\n",
        "                - (float): reward for reaching and grasping\n",
        "                - (float): reward for lifting and aligning\n",
        "                - (float): reward for stacking\n",
        "        \"\"\"\n",
        "        # reaching is successful when the gripper site is close to the center of the cube\n",
        "        cubeA_pos = self.sim.data.body_xpos[self.cubeA_body_id]\n",
        "        cubeB_pos = self.sim.data.body_xpos[self.cubeB_body_id]\n",
        "        gripper_site_pos = self.sim.data.site_xpos[self.robots[0].eef_site_id]\n",
        "        dist = np.linalg.norm(gripper_site_pos - cubeA_pos)\n",
        "        r_reach = (1 - np.tanh(10.0 * dist)) * 0.25\n",
        "\n",
        "        # grasping reward\n",
        "        grasping_cubeA = self._check_grasp(gripper=self.robots[0].gripper, object_geoms=self.cubeA)\n",
        "        if grasping_cubeA:\n",
        "            r_reach += 0.25\n",
        "\n",
        "        # lifting is successful when the cube is above the table top by a margin\n",
        "        cubeA_height = cubeA_pos[2]\n",
        "        table_height = self.table_offset[2]\n",
        "        cubeA_lifted = cubeA_height > table_height + 0.04\n",
        "        r_lift = 1.0 if cubeA_lifted else 0.0\n",
        "\n",
        "        # Aligning is successful when cubeA is right above cubeB\n",
        "        if cubeA_lifted:\n",
        "            horiz_dist = np.linalg.norm(np.array(cubeA_pos[:2]) - np.array(cubeB_pos[:2]))\n",
        "            r_lift += 0.5 * (1 - np.tanh(horiz_dist))\n",
        "\n",
        "        # stacking is successful when the block is lifted and the gripper is not holding the object\n",
        "        r_stack = 0\n",
        "        cubeA_touching_cubeB = self.check_contact(self.cubeA, self.cubeB)\n",
        "        if not grasping_cubeA and r_lift > 0 and cubeA_touching_cubeB:\n",
        "            r_stack = 2.0\n",
        "\n",
        "        return r_reach, r_lift, r_stack\n",
        "\n",
        "    def _load_model(self):\n",
        "        \"\"\"\n",
        "        Loads an xml model, puts it in self.model\n",
        "        \"\"\"\n",
        "        super()._load_model()\n",
        "\n",
        "        # Adjust base pose accordingly\n",
        "        xpos = self.robots[0].robot_model.base_xpos_offset[\"table\"](self.table_full_size[0])\n",
        "        self.robots[0].robot_model.set_base_xpos(xpos)\n",
        "\n",
        "        # load model for table top workspace\n",
        "        mujoco_arena = TableArena(\n",
        "            table_full_size=self.table_full_size,\n",
        "            table_friction=self.table_friction,\n",
        "            table_offset=self.table_offset,\n",
        "        )\n",
        "\n",
        "        # Arena always gets set to zero origin\n",
        "        mujoco_arena.set_origin([0, 0, 0])\n",
        "\n",
        "        # initialize objects of interest\n",
        "        tex_attrib = {\n",
        "            \"type\": \"cube\",\n",
        "        }\n",
        "        mat_attrib = {\n",
        "            \"texrepeat\": \"1 1\",\n",
        "            \"specular\": \"0.4\",\n",
        "            \"shininess\": \"0.1\",\n",
        "        }\n",
        "        redwood = CustomMaterial(\n",
        "            texture=\"WoodRed\",\n",
        "            tex_name=\"redwood\",\n",
        "            mat_name=\"redwood_mat\",\n",
        "            tex_attrib=tex_attrib,\n",
        "            mat_attrib=mat_attrib,\n",
        "        )\n",
        "        greenwood = CustomMaterial(\n",
        "            texture=\"WoodGreen\",\n",
        "            tex_name=\"greenwood\",\n",
        "            mat_name=\"greenwood_mat\",\n",
        "            tex_attrib=tex_attrib,\n",
        "            mat_attrib=mat_attrib,\n",
        "        )\n",
        "        self.cubeA = BoxObject(\n",
        "            name=\"cubeA\",\n",
        "            size_min=[0.02, 0.02, 0.02],\n",
        "            size_max=[0.02, 0.02, 0.02],\n",
        "            rgba=[1, 0, 0, 1],\n",
        "            material=redwood,\n",
        "        )\n",
        "        self.cubeB = BoxObject(\n",
        "            name=\"cubeB\",\n",
        "            size_min=[0.025, 0.025, 0.025],\n",
        "            size_max=[0.025, 0.025, 0.025],\n",
        "            rgba=[0, 1, 0, 1],\n",
        "            material=greenwood,\n",
        "        )\n",
        "        cubes = [self.cubeA, self.cubeB]\n",
        "        # Create placement initializer\n",
        "        if self.placement_initializer is not None:\n",
        "            self.placement_initializer.reset()\n",
        "            self.placement_initializer.add_objects(cubes)\n",
        "        else:\n",
        "            self.placement_initializer = UniformRandomSampler(\n",
        "                name=\"ObjectSampler\",\n",
        "                mujoco_objects=cubes,\n",
        "                x_range=[-0.08, 0.08],\n",
        "                y_range=[-0.08, 0.08],\n",
        "                rotation=None,\n",
        "                ensure_object_boundary_in_range=False,\n",
        "                ensure_valid_placement=True,\n",
        "                reference_pos=self.table_offset,\n",
        "                z_offset=0.01,\n",
        "            )\n",
        "\n",
        "        # task includes arena, robot, and objects of interest\n",
        "        self.model = ManipulationTask(\n",
        "            mujoco_arena=mujoco_arena,\n",
        "            mujoco_robots=[robot.robot_model for robot in self.robots],\n",
        "            mujoco_objects=cubes,\n",
        "        )\n",
        "\n",
        "    def _setup_references(self):\n",
        "        \"\"\"\n",
        "        Sets up references to important components. A reference is typically an\n",
        "        index or a list of indices that point to the corresponding elements\n",
        "        in a flatten array, which is how MuJoCo stores physical simulation data.\n",
        "        \"\"\"\n",
        "        super()._setup_references()\n",
        "\n",
        "        # Additional object references from this env\n",
        "        self.cubeA_body_id = self.sim.model.body_name2id(self.cubeA.root_body)\n",
        "        self.cubeB_body_id = self.sim.model.body_name2id(self.cubeB.root_body)\n",
        "\n",
        "    def _reset_internal(self):\n",
        "        \"\"\"\n",
        "        Resets simulation internal configurations.\n",
        "        \"\"\"\n",
        "        super()._reset_internal()\n",
        "\n",
        "        self.robots[0].set_robot_joint_positions(self.joint_pos)\n",
        "\n",
        "        # Reset all object positions using initializer sampler if we're not directly loading from an xml\n",
        "        if not self.deterministic_reset:\n",
        "\n",
        "            # Sample from the placement initializer for all objects\n",
        "            object_placements = self.placement_initializer.sample()\n",
        "\n",
        "            # Loop through all objects and reset their positions\n",
        "            for obj_pos, obj_quat, obj in object_placements.values():\n",
        "              self.sim.data.set_joint_qpos(obj.joints[0], np.concatenate([np.array(obj_pos), np.array(obj_quat)]))\n",
        "\n",
        "        else:\n",
        "          self.sim.data.set_joint_qpos(obj.joints[0], np.concatenate([self.obj_pos, self.obj_quat]))\n",
        "\n",
        "    def _setup_observables(self):\n",
        "        \"\"\"\n",
        "        Sets up observables to be used for this environment. Creates object-based observables if enabled\n",
        "\n",
        "        Returns:\n",
        "            OrderedDict: Dictionary mapping observable names to its corresponding Observable object\n",
        "        \"\"\"\n",
        "        observables = super()._setup_observables()\n",
        "\n",
        "        # low-level object information\n",
        "        if self.use_object_obs:\n",
        "            # Get robot prefix and define observables modality\n",
        "            pf = self.robots[0].robot_model.naming_prefix\n",
        "            modality = \"object\"\n",
        "\n",
        "            # position and rotation of the first cube\n",
        "            @sensor(modality=modality)\n",
        "            def cubeA_pos(obs_cache):\n",
        "                return np.array(self.sim.data.body_xpos[self.cubeA_body_id])\n",
        "\n",
        "            @sensor(modality=modality)\n",
        "            def cubeA_quat(obs_cache):\n",
        "                return convert_quat(np.array(self.sim.data.body_xquat[self.cubeA_body_id]), to=\"xyzw\")\n",
        "\n",
        "            @sensor(modality=modality)\n",
        "            def cubeB_pos(obs_cache):\n",
        "                return np.array(self.sim.data.body_xpos[self.cubeB_body_id])\n",
        "\n",
        "            @sensor(modality=modality)\n",
        "            def cubeB_quat(obs_cache):\n",
        "                return convert_quat(np.array(self.sim.data.body_xquat[self.cubeB_body_id]), to=\"xyzw\")\n",
        "\n",
        "            @sensor(modality=modality)\n",
        "            def gripper_to_cubeA(obs_cache):\n",
        "                return (\n",
        "                    obs_cache[\"cubeA_pos\"] - obs_cache[f\"{pf}eef_pos\"]\n",
        "                    if \"cubeA_pos\" in obs_cache and f\"{pf}eef_pos\" in obs_cache\n",
        "                    else np.zeros(3)\n",
        "                )\n",
        "\n",
        "            @sensor(modality=modality)\n",
        "            def gripper_to_cubeB(obs_cache):\n",
        "                return (\n",
        "                    obs_cache[\"cubeB_pos\"] - obs_cache[f\"{pf}eef_pos\"]\n",
        "                    if \"cubeB_pos\" in obs_cache and f\"{pf}eef_pos\" in obs_cache\n",
        "                    else np.zeros(3)\n",
        "                )\n",
        "\n",
        "            @sensor(modality=modality)\n",
        "            def cubeA_to_cubeB(obs_cache):\n",
        "                return (\n",
        "                    obs_cache[\"cubeB_pos\"] - obs_cache[\"cubeA_pos\"]\n",
        "                    if \"cubeA_pos\" in obs_cache and \"cubeB_pos\" in obs_cache\n",
        "                    else np.zeros(3)\n",
        "                )\n",
        "\n",
        "            sensors = [cubeA_pos, cubeA_quat, cubeB_pos, cubeB_quat, gripper_to_cubeA, gripper_to_cubeB, cubeA_to_cubeB]\n",
        "            names = [s.__name__ for s in sensors]\n",
        "\n",
        "            # Create observables\n",
        "            for name, s in zip(names, sensors):\n",
        "                observables[name] = Observable(\n",
        "                    name=name,\n",
        "                    sensor=s,\n",
        "                    sampling_rate=self.control_freq,\n",
        "                )\n",
        "\n",
        "        return observables\n",
        "\n",
        "    def _check_success(self):\n",
        "        \"\"\"\n",
        "        Check if blocks are stacked correctly.\n",
        "\n",
        "        Returns:\n",
        "            bool: True if blocks are correctly stacked\n",
        "        \"\"\"\n",
        "        _, _, r_stack = self.staged_rewards()\n",
        "        return r_stack > 0\n",
        "\n",
        "    def visualize(self, vis_settings):\n",
        "        \"\"\"\n",
        "        In addition to super call, visualize gripper site proportional to the distance to the cube.\n",
        "\n",
        "        Args:\n",
        "            vis_settings (dict): Visualization keywords mapped to T/F, determining whether that specific\n",
        "                component should be visualized. Should have \"grippers\" keyword as well as any other relevant\n",
        "                options specified.\n",
        "        \"\"\"\n",
        "        # Run superclass method first\n",
        "        super().visualize(vis_settings=vis_settings)\n",
        "\n",
        "        # Color the gripper visualization site according to its distance to the cube\n",
        "        if vis_settings[\"grippers\"]:\n",
        "            self._visualize_gripper_to_target(gripper=self.robots[0].gripper, target=self.cubeA)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Y9wPT6c3nUjQ"
      },
      "outputs": [],
      "source": [
        "class PrioritizedReplayBuffer(ReplayBuffer):\n",
        "    \"\"\"Implementation of Prioritized Experience Replay. arXiv:1511.05952.\n",
        "\n",
        "    :param float alpha: the prioritization exponent.\n",
        "    :param float beta: the importance sample soft coefficient.\n",
        "    :param bool weight_norm: whether to normalize returned weights with the maximum\n",
        "        weight value within the batch. Default to True.\n",
        "\n",
        "    .. seealso::\n",
        "\n",
        "        Please refer to :class:`~tianshou.data.ReplayBuffer` for other APIs' usage.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        size: int,\n",
        "        alpha: float,\n",
        "        beta: float,\n",
        "        weight_norm: bool = True,\n",
        "        **kwargs: Any\n",
        "    ) -> None:\n",
        "        # will raise KeyError in PrioritizedVectorReplayBuffer\n",
        "        # super().__init__(size, **kwargs)\n",
        "        ReplayBuffer.__init__(self, size, **kwargs)\n",
        "        assert alpha > 0.0 and beta >= 0.0\n",
        "        self._alpha, self._beta = alpha, beta\n",
        "        self._max_prio = self._min_prio = 1.0\n",
        "        # save weight directly in this class instead of self._meta\n",
        "        self.weight = SegmentTree(size)\n",
        "        self.__eps = np.finfo(np.float32).eps.item()\n",
        "        self.options.update(alpha=alpha, beta=beta)\n",
        "        self._weight_norm = weight_norm\n",
        "\n",
        "    def init_weight(self, index: Union[int, np.ndarray]) -> None:\n",
        "        self.weight[index] = self._max_prio**self._alpha\n",
        "\n",
        "\n",
        "    def update(self, buffer: ReplayBuffer) -> np.ndarray:\n",
        "        indices = super().update(buffer)\n",
        "        self.init_weight(indices)\n",
        "        return indices\n",
        "\n",
        "\n",
        "    def add(\n",
        "        self,\n",
        "        batch: Batch,\n",
        "        buffer_ids: Optional[Union[np.ndarray, List[int]]] = None\n",
        "    ) -> Tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray]:\n",
        "        ptr, ep_rew, ep_len, ep_idx = super().add(batch, buffer_ids)\n",
        "        self.init_weight(ptr)\n",
        "        return ptr, ep_rew, ep_len, ep_idx\n",
        "\n",
        "\n",
        "    def sample_indices(self, batch_size: int) -> np.ndarray:\n",
        "        if batch_size > 0 and len(self) > 0:\n",
        "            scalar = np.random.rand(batch_size) * self.weight.reduce()\n",
        "            return self.weight.get_prefix_sum_idx(scalar)  # type: ignore\n",
        "        else:\n",
        "            return super().sample_indices(batch_size)\n",
        "\n",
        "\n",
        "    def get_weight(self, index: Union[int, np.ndarray]) -> Union[float, np.ndarray]:\n",
        "        \"\"\"Get the importance sampling weight.\n",
        "\n",
        "        The \"weight\" in the returned Batch is the weight on loss function to debias\n",
        "        the sampling process (some transition tuples are sampled more often so their\n",
        "        losses are weighted less).\n",
        "        \"\"\"\n",
        "        # important sampling weight calculation\n",
        "        # original formula: ((p_j/p_sum*N)**(-beta))/((p_min/p_sum*N)**(-beta))\n",
        "        # simplified formula: (p_j/p_min)**(-beta)\n",
        "        return (self.weight[index] / self._min_prio)**(-self._beta)\n",
        "\n",
        "\n",
        "    def update_weight(\n",
        "        self, index: np.ndarray, new_weight: Union[np.ndarray, torch.Tensor]\n",
        "    ) -> None:\n",
        "        \"\"\"Update priority weight by index in this buffer.\n",
        "\n",
        "        :param np.ndarray index: index you want to update weight.\n",
        "        :param np.ndarray new_weight: new priority weight you want to update.\n",
        "        \"\"\"\n",
        "        weight = np.abs(to_numpy(new_weight)) + self.__eps\n",
        "        self.weight[index] = weight**self._alpha\n",
        "        self._max_prio = max(self._max_prio, weight.max())\n",
        "        self._min_prio = min(self._min_prio, weight.min())\n",
        "\n",
        "\n",
        "    def __getitem__(self, index: Union[slice, int, List[int], np.ndarray]) -> Batch:\n",
        "        if isinstance(index, slice):  # change slice to np array\n",
        "            # buffer[:] will get all available data\n",
        "            indices = self.sample_indices(0) if index == slice(None) \\\n",
        "                else self._indices[:len(self)][index]\n",
        "        else:\n",
        "            indices = index  # type: ignore\n",
        "        batch = super().__getitem__(indices)\n",
        "        weight = self.get_weight(indices)\n",
        "        # ref: https://github.com/Kaixhin/Rainbow/blob/master/memory.py L154\n",
        "        batch.weight = weight / np.max(weight) if self._weight_norm else weight\n",
        "        return batch\n",
        "\n",
        "\n",
        "    def set_beta(self, beta: float) -> None:\n",
        "        self._beta = beta"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "HwtCkUQ-njAo"
      },
      "outputs": [],
      "source": [
        "class OrnsteinUhlenbeckProcess:\n",
        "    def __init__(self, theta=0.15, mu=0.0, sigma=0.2, dt=1e-2, x0=None, size=1, sigma_min=None, n_steps_annealing=1000):\n",
        "        self.theta = theta\n",
        "        self.mu = mu\n",
        "        self.sigma = sigma\n",
        "        self.dt = dt\n",
        "        self.x0 = x0\n",
        "        self.size = size\n",
        "        self.num_steps = 0\n",
        "\n",
        "        self.x_prev = self.x0 if self.x0 is not None else np.zeros(self.size)\n",
        "\n",
        "        if sigma_min is not None:\n",
        "            self.m = -float(sigma - sigma_min) / float(n_steps_annealing)\n",
        "            self.c = sigma\n",
        "            self.sigma_min = sigma_min\n",
        "        else:\n",
        "            self.m = 0\n",
        "            self.c = sigma\n",
        "            self.sigma_min = sigma\n",
        "\n",
        "    def current_sigma(self):\n",
        "        sigma = max(self.sigma_min, self.m * float(self.num_steps) + self.c)\n",
        "        return sigma\n",
        "\n",
        "    def sample(self):\n",
        "        x = self.x_prev + self.theta * (self.mu - self.x_prev) * self.dt + self.current_sigma() * np.sqrt(self.dt) * np.random.normal(size=self.size)\n",
        "        self.x_prev = x\n",
        "        self.num_steps += 1\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "xHYlEFBGmGd-"
      },
      "outputs": [],
      "source": [
        "class Actor(nn.Module):\n",
        "    def __init__(self, action_shape):\n",
        "      super().__init__()\n",
        "      self.model = torch.nn.Sequential(\n",
        "          # CNN Layers\n",
        "          torch.nn.Conv2d(1, 32, kernel_size=8, stride=4),\n",
        "          torch.nn.ReLU(),\n",
        "          torch.nn.Conv2d(32, 64, kernel_size=4, stride=2),\n",
        "          torch.nn.ReLU(),\n",
        "          torch.nn.Conv2d(64, 64, kernel_size=3, stride=1),\n",
        "          torch.nn.ReLU(),\n",
        "          torch.nn.Flatten(),\n",
        "          # Fully Connected Layers\n",
        "          torch.nn.Linear(1024, 256),\n",
        "          torch.nn.ReLU(),\n",
        "          torch.nn.Linear(256, action_shape)\n",
        "      )\n",
        "\n",
        "    def forward(self, obs):\n",
        "        action = self.model(obs)\n",
        "        return action\n",
        "\n",
        "\n",
        "class Critic(nn.Module):\n",
        "    def __init__(self, action_shape):\n",
        "        super(Critic, self).__init__()\n",
        "\n",
        "        # CNN Layers for processing the observation\n",
        "        self.obs_net = nn.Sequential(\n",
        "            nn.Conv2d(1, 32, kernel_size=8, stride=4),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(32, 64, kernel_size=4, stride=2),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(64, 64, kernel_size=3, stride=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Flatten()\n",
        "        )\n",
        "\n",
        "        # Fully Connected Layers\n",
        "        # Assuming the flattened output from CNN is of size 1024\n",
        "        # We concatenate it with the action tensor, so the input size becomes 1024 + action_shape\n",
        "        self.fc_net = nn.Sequential(\n",
        "            nn.Linear(1024 + action_shape, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(256, 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, obs, act):\n",
        "\n",
        "      if not isinstance(obs, torch.Tensor):\n",
        "        obs = torch.tensor(obs, dtype=torch.float32)\n",
        "      if not isinstance(act, torch.Tensor):\n",
        "        act = torch.tensor(act, dtype=torch.float32)\n",
        "\n",
        "      obs_repr = self.obs_net(obs)\n",
        "\n",
        "      # Concatenate the CNN output with the action tensor along dimension 1 (columns)\n",
        "      combined = torch.cat([obs_repr, act], dim=1)\n",
        "\n",
        "      q_value = self.fc_net(combined)\n",
        "\n",
        "      return q_value"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "noyX366il72l"
      },
      "outputs": [],
      "source": [
        "class Learner:\n",
        "    def __init__(self, action_shape, num_agent, gamma=0.95,lr=0.001,batch_size=1024,memory_size=int(1e6),tau=0.01,grad_norm_clipping = 0.5):\n",
        "        self.action_shape = action_shape\n",
        "        self.gamma = gamma\n",
        "        self.actor = Actor(self.action_shape)\n",
        "        self.target_actor = copy.deepcopy(self.actor)\n",
        "        self.actor_optimizer = optim.Adam(self.actor.parameters(),lr=lr)\n",
        "        self.critic = Critic(self.action_shape)\n",
        "        self.target_critic = copy.deepcopy(self.critic)\n",
        "        self.critic_optimizer = optim.Adam(self.critic.parameters(),lr=lr)\n",
        "\n",
        "        # Wrap your models with DataParallel\n",
        "        if torch.cuda.device_count() > 1:\n",
        "          print(\"Using\", torch.cuda.device_count(), \"GPUs!\")\n",
        "          self.actor = torch.nn.DataParallel(self.actor)\n",
        "          self.target_actor = torch.nn.DataParallel(self.target_actor)\n",
        "          self.critic = torch.nn.DataParallel(self.critic)\n",
        "          self.target_critic = torch.nn.DataParallel(self.target_critic)\n",
        "        else:\n",
        "          self.actor = self.actor.to(device)\n",
        "          self.target_actor = self.target_actor.to(device)\n",
        "          self.critic = self.critic.to(device)\n",
        "          self.target_critic = self.target_critic.to(device)\n",
        "\n",
        "        self.pri_buffer = PrioritizedReplayBuffer(memory_size, alpha=0.6, beta=0.4)\n",
        "        self.loss_fn = torch.nn.MSELoss()\n",
        "        self.batch_size = batch_size\n",
        "        self.is_gpu = torch.cuda.is_available\n",
        "        self.noise = OrnsteinUhlenbeckProcess(size=self.action_shape)\n",
        "        self.grad_norm_clipping = grad_norm_clipping\n",
        "        self.tau = tau\n",
        "        self.num_agent = num_agent\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def td_targeti(self,reward,obs,next_obs,done):\n",
        "        next_action = torch.tanh(self.target_actor(obs))\n",
        "        next_q = self.target_critic(next_obs,next_action)\n",
        "        td_targeti = reward.unsqueeze(1) + self.gamma * next_q*(1.-done.unsqueeze(1))\n",
        "        return td_targeti.float()\n",
        "\n",
        "    def update(self):\n",
        "      indice = self.pri_buffer.sample_indices(self.batch_size)\n",
        "      sample = self.pri_buffer.__getitem__(indice)\n",
        "      obs, action, reward, next_obs, done = sample['obs'], sample['act'], sample['rew'], sample['obs_next'], sample['terminated']\n",
        "\n",
        "      obs = obs.to(device)\n",
        "      next_obs = next_obs.to(device)\n",
        "      action = action.to(device)\n",
        "\n",
        "      reward = torch.FloatTensor(reward).to(device)\n",
        "      done = np.array(done)\n",
        "      done = torch.IntTensor(done).to(device)\n",
        "\n",
        "      td_targeti = self.td_targeti(reward,obs,next_obs,done)\n",
        "      current_q = self.critic(obs,action)\n",
        "\n",
        "      critic_loss = self.loss_fn(current_q,td_targeti)\n",
        "      \"\"\" Update priorities based on TD errors \"\"\"\n",
        "      td_errors = (td_targeti - current_q).t()          # Calculate the TD Errors\n",
        "      self.pri_buffer.update_weight(indice, td_errors.data.detach().cpu().numpy())\n",
        "\n",
        "      self.critic_optimizer.zero_grad()\n",
        "      critic_loss.backward()\n",
        "      clip_grad_norm_(self.critic.parameters(),max_norm=self.grad_norm_clipping)\n",
        "      self.critic_optimizer.step()\n",
        "      ac_up = self.actor(obs)\n",
        "      ac = torch.tanh(ac_up)\n",
        "      pr = -self.critic(obs,ac).mean()\n",
        "      pg = (ac.pow(2)).mean()\n",
        "      actor_loss = pr + pg*1e-3\n",
        "      self.actor_optimizer.zero_grad()\n",
        "      clip_grad_norm_(self.actor.parameters(),max_norm=self.grad_norm_clipping)\n",
        "      actor_loss.backward()\n",
        "      self.actor_optimizer.step()\n",
        "\n",
        "      for target_param, param in zip(self.target_actor.parameters(), self.actor.parameters()):\n",
        "        target_param.data.copy_(self.tau * param.data + (1.0 - self.tau) * target_param.data)\n",
        "      for target_param, param in zip(self.target_critic.parameters(), self.critic.parameters()):\n",
        "        target_param.data.copy_(self.tau * param.data + (1.0 - self.tau) * target_param.data)\n",
        "\n",
        "    def inference(self,obs,greedy=False):\n",
        "        obs = obs.to(device)\n",
        "        action = torch.tanh(self.actor(obs))\n",
        "        if not greedy:\n",
        "            action += torch.tensor(self.noise.sample(),dtype=torch.float).cuda()\n",
        "        return np.clip(action.detach().cpu().numpy(),-1.0,1.0)\n",
        "\n",
        "    def load_checkpoint(self, filename):\n",
        "      checkpoint = torch.load(filename)\n",
        "\n",
        "      self.actor.load_state_dict(checkpoint['actor_state_dict'])\n",
        "      self.target_actor.load_state_dict(checkpoint['target_actor_state_dict'])\n",
        "      self.actor_optimizer.load_state_dict(checkpoint['actor_optimizer_state_dict'])\n",
        "\n",
        "      self.critic.load_state_dict(checkpoint['critic_state_dict'])\n",
        "      self.target_critic.load_state_dict(checkpoint['target_critic_state_dict'])\n",
        "      self.critic_optimizer.load_state_dict(checkpoint['critic_optimizer_state_dict'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "yIdI7jX871A3"
      },
      "outputs": [],
      "source": [
        "class Agent:\n",
        "    def __init__(self, num_agent, learner):\n",
        "        self.num_agent = num_agent\n",
        "        self.learner = learner\n",
        "\n",
        "    def get_action(self,states, greedy=False):\n",
        "      actions = self.learner.inference(states)\n",
        "      return actions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "DJhTTGWYk6S9"
      },
      "outputs": [],
      "source": [
        "def imagePreProcess(obs):\n",
        "    obs = torch.tensor(obs.transpose(2, 0, 1), dtype=torch.float32).unsqueeze(0)\n",
        "    obs = 0.2989 * obs[:, 0, :, :] + 0.5870 * obs[:, 1, :, :] + 0.1140 * obs[:, 2, :, :]\n",
        "    obs = obs.unsqueeze(1)\n",
        "    obs = F.interpolate(obs, size=(64, 64), mode='bilinear', align_corners=False)\n",
        "    return obs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gyfdtHUZDZ1R",
        "outputId": "31ef0bd1-60b5-4953-9e36-a46dfd9a4ede"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ],
      "source": [
        "num_agent = 2\n",
        "num_episode = 1000\n",
        "initial_memory_size = 1000\n",
        "memory_size = 1000\n",
        "episode_rewards = []\n",
        "num_average_epidodes = 100\n",
        "save_every = 500\n",
        "batch_size=3072\n",
        "max_steps = 100\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)\n",
        "\n",
        "envs = [Stack('Panda') for _ in range(num_agent)]\n",
        "\n",
        "action_shape = envs[0].robots[0].robot_model.dof + envs[0].robots[0].gripper.dof\n",
        "\n",
        "learner = Learner(action_shape, num_agent, memory_size)\n",
        "agent = Agent(num_agent, learner)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IQn_MERbaT1U"
      },
      "source": [
        "## Initialize memory buffer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LTWAbGjsaT9F",
        "outputId": "761108f5-4625-4cd2-ebb2-d844d8ad353e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2000 Data collected\n"
          ]
        }
      ],
      "source": [
        "\"\"\" Reset the environment \"\"\"\n",
        "states = [OrderedDict() for _ in range(num_agent)]\n",
        "next_states = [OrderedDict() for _ in range(num_agent)]\n",
        "dones = [False for _ in range(num_agent)]\n",
        "rewards = [0 for _ in range(num_agent)]\n",
        "\n",
        "for i in range(num_agent):\n",
        "  states[i] = envs[i].reset()\n",
        "\n",
        "\"\"\" Initially, put the data into the replay buffer when an action with noise was taken \"\"\"\n",
        "for step in range(initial_memory_size):\n",
        "  for i in range(num_agent):\n",
        "    if step % max_steps == 0:\n",
        "      states[i] = envs[i].reset()\n",
        "\n",
        "    obs = imagePreProcess(states[i]['frontview_image'])\n",
        "\n",
        "    action = np.random.randn(action_shape) # sample random action\n",
        "    next_states[i], rewards[i], dones[i], info = envs[i].step(action)\n",
        "\n",
        "    obs_next = imagePreProcess(next_states[i]['frontview_image'])\n",
        "\n",
        "    obs = obs.squeeze(0)\n",
        "    obs_next = obs_next.squeeze(0)\n",
        "    action = torch.tensor(action, dtype=torch.float32)\n",
        "    action = action.squeeze(0)\n",
        "\n",
        "    batch = Batch({'obs': obs, 'act': action, 'rew': rewards[i], 'obs_next': obs_next, 'terminated': dones[i], 'truncated': dones[i]})\n",
        "\n",
        "    agent.learner.pri_buffer.add(batch)\n",
        "    states[i] = next_states[i]\n",
        "print('%d Data collected' % (initial_memory_size*num_agent))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OvtZ6Z_taf3M"
      },
      "source": [
        "## Train agent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ilSkkI7apWmY",
        "outputId": "4bc1ba23-7b38-4c7d-b977-f7ca2c8b735c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 0 finished | Episode reward 0.000425\n",
            "Model Saved\n"
          ]
        }
      ],
      "source": [
        "\"\"\" Train model \"\"\"\n",
        "for episode in range(num_episode):\n",
        "  for i in range(num_agent):\n",
        "    states[i] = envs[i].reset()\n",
        "  episode_reward = 0\n",
        "  for t in range(max_steps):\n",
        "    for i in range(num_agent):\n",
        "      obs = imagePreProcess(states[i]['frontview_image'])\n",
        "\n",
        "      action = agent.get_action(obs)\n",
        "      next_states[i], rewards[i], dones[i], info = envs[i].step(action[0])\n",
        "\n",
        "      obs_next = imagePreProcess(next_states[i]['frontview_image'])\n",
        "\n",
        "      obs = obs.squeeze(0)\n",
        "      obs_next = obs_next.squeeze(0)\n",
        "      action = torch.tensor(action, dtype=torch.float32)\n",
        "      action = action.squeeze(0)\n",
        "\n",
        "      batch = Batch({'obs': obs, 'act': action, 'rew': rewards[i], 'obs_next': obs_next, 'terminated': dones[i], 'truncated': dones[i]})\n",
        "      agent.learner.pri_buffer.add(batch)\n",
        "      states[i] = next_states[i]\n",
        "      if any(dones):\n",
        "        break\n",
        "\n",
        "    episode_reward += sum(rewards)\n",
        "  if episode % 5 == 0:\n",
        "    agent.learner.update()\n",
        "  episode_rewards.append(episode_reward)\n",
        "  if episode % 100 == 0:\n",
        "    print(\"Episode %d finished | Episode reward %f\" % (episode, episode_reward))\n",
        "  if episode % save_every == 0:\n",
        "    checkpoint = {'episode': episode,\n",
        "    'actor_state_dict': agent.learner.actor.state_dict(),\n",
        "    'target_actor_state_dict': agent.learner.target_actor.state_dict(),\n",
        "    'actor_optimizer_state_dict': agent.learner.actor_optimizer.state_dict(),\n",
        "    'critic_state_dict': agent.learner.critic.state_dict(),\n",
        "    'target_critic_state_dict': agent.learner.target_critic.state_dict(),\n",
        "    'critic_optimizer_state_dict': agent.learner.critic_optimizer.state_dict()}\n",
        "    torch.save(checkpoint, 'check_point')\n",
        "    print('Model Saved')\n",
        "\n",
        "for i in range(num_agent):\n",
        "  envs[i].close()\n",
        "\n",
        "# Compute the moving average of cumulative rewards\n",
        "moving_average = np.convolve(episode_rewards, np.ones(num_average_epidodes)/num_average_epidodes, mode='valid')\n",
        "plt.plot(np.arange(len(moving_average)),moving_average)\n",
        "plt.title('Average rewards in %d episodes' % num_average_epidodes)\n",
        "plt.xlabel('episode')\n",
        "plt.ylabel('rewards')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2rgxoeCJaoK8"
      },
      "source": [
        "## Test Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NRpDqBbitbMT"
      },
      "outputs": [],
      "source": [
        "\"\"\" Reset the environment \"\"\"\n",
        "env = Stack('Panda')\n",
        "states = env.reset()\n",
        "\n",
        "agent.learner.load_checkpoint('check_point')\n",
        "\n",
        "frames = []\n",
        "for i in range(100):\n",
        "\n",
        "    frames.append(states['frontview_image'])  # Append the image to the frames list\n",
        "    obs = imagePreProcess(states['frontview_image'])\n",
        "\n",
        "    actions = agent.get_action(obs)\n",
        "\n",
        "    next_states, rewards, dones, info = env.step(actions[0])\n",
        "    states = next_states\n",
        "\n",
        "    # if i == 50:\n",
        "    #   env.joint_pos = np.array([0.0, 0.5, 1.0, 1.3, 1.0, 1.0, 0.785])\n",
        "    #   env.object_pos = np.array([10,10,0])\n",
        "    #   env.object_quat = np.array([1, 0, 0])\n",
        "    #   states = env.reset()\n",
        "\n",
        "\n",
        "imageio.mimwrite('robosuite_video.mp4', frames, fps=20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cYRnB8zG3QPL"
      },
      "outputs": [],
      "source": [
        "\"\"\" Load video and encode it in base64 format \"\"\"\n",
        "video_path = 'robosuite_video.mp4'\n",
        "video_data = open(video_path, 'rb').read()\n",
        "video_encoded = b64encode(video_data).decode()\n",
        "\n",
        "# Display video using HTML\n",
        "HTML(f\"\"\"\n",
        "<video width=\"640\" height=\"480\" controls>\n",
        "  <source src=\"data:video/mp4;base64,{video_encoded}\" type=\"video/mp4\">\n",
        "</video>\n",
        "\"\"\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}