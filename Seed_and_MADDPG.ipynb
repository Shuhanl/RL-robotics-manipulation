{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "If6ejBKyQlcz",
        "outputId": "0dc43974-3aa5-4ef9-bf81-60ab495ff3e4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'multiagent-particle-envs'...\n",
            "remote: Enumerating objects: 281, done.\u001b[K\n",
            "remote: Counting objects: 100% (123/123), done.\u001b[K\n",
            "remote: Compressing objects: 100% (35/35), done.\u001b[K\n",
            "remote: Total 281 (delta 104), reused 88 (delta 88), pack-reused 158\u001b[K\n",
            "Receiving objects: 100% (281/281), 109.97 KiB | 908.00 KiB/s, done.\n",
            "Resolving deltas: 100% (158/158), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/openai/multiagent-particle-envs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VEcuSBdHQpfd",
        "outputId": "feb2a18e-fe93-4cea-ea76-98ef4c4dd1af"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: JSAnimation in /usr/local/lib/python3.10/dist-packages (0.1)\n"
          ]
        }
      ],
      "source": [
        "!apt-get install -y xvfb > /dev/null 2>&1\n",
        "!pip install gym pyvirtualdisplay > /dev/null 2>&1\n",
        "!pip install JSAnimation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rs9Qkq5fQ0IU",
        "outputId": "fb034b7e-743d-4bcb-c761-a39d034c5307"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/multiagent-particle-envs/multiagent-particle-envs/multiagent-particle-envs/multiagent-particle-envs\n"
          ]
        }
      ],
      "source": [
        "cd multiagent-particle-envs/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LZLZ2fF3Q29T",
        "outputId": "a19b1d9e-988d-4a09-93f0-ebeadfc903d8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gym==0.10.5 in /usr/local/lib/python3.10/dist-packages (0.10.5)\n",
            "Requirement already satisfied: numpy>=1.10.4 in /usr/local/lib/python3.10/dist-packages (from gym==0.10.5) (1.23.5)\n",
            "Requirement already satisfied: requests>=2.0 in /usr/local/lib/python3.10/dist-packages (from gym==0.10.5) (2.31.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from gym==0.10.5) (1.16.0)\n",
            "Requirement already satisfied: pyglet>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gym==0.10.5) (1.3.2)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from pyglet>=1.2.0->gym==0.10.5) (0.18.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.0->gym==0.10.5) (3.3.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.0->gym==0.10.5) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.0->gym==0.10.5) (2.0.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.0->gym==0.10.5) (2023.7.22)\n",
            "Requirement already satisfied: pyglet==1.3.2 in /usr/local/lib/python3.10/dist-packages (1.3.2)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from pyglet==1.3.2) (0.18.3)\n",
            "Requirement already satisfied: tianshou in /usr/local/lib/python3.10/dist-packages (0.5.1)\n",
            "Requirement already satisfied: gymnasium>=0.26.0 in /usr/local/lib/python3.10/dist-packages (from tianshou) (0.29.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from tianshou) (4.66.1)\n",
            "Requirement already satisfied: numpy>1.16.0 in /usr/local/lib/python3.10/dist-packages (from tianshou) (1.23.5)\n",
            "Requirement already satisfied: tensorboard>=2.5.0 in /usr/local/lib/python3.10/dist-packages (from tianshou) (2.13.0)\n",
            "Requirement already satisfied: torch>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from tianshou) (2.0.1+cu118)\n",
            "Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.10/dist-packages (from tianshou) (0.56.4)\n",
            "Requirement already satisfied: h5py>=2.10.0 in /usr/local/lib/python3.10/dist-packages (from tianshou) (3.9.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tianshou) (23.2)\n",
            "Requirement already satisfied: pettingzoo>=1.22 in /usr/local/lib/python3.10/dist-packages (from tianshou) (1.24.1)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium>=0.26.0->tianshou) (2.2.1)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium>=0.26.0->tianshou) (4.5.0)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from gymnasium>=0.26.0->tianshou) (0.0.4)\n",
            "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.51.0->tianshou) (0.39.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from numba>=0.51.0->tianshou) (67.7.2)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.5.0->tianshou) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.5.0->tianshou) (1.59.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.5.0->tianshou) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.5.0->tianshou) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.5.0->tianshou) (3.5)\n",
            "Requirement already satisfied: protobuf>=3.19.6 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.5.0->tianshou) (3.20.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.5.0->tianshou) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.5.0->tianshou) (0.7.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.5.0->tianshou) (3.0.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.5.0->tianshou) (0.41.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->tianshou) (3.12.4)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->tianshou) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->tianshou) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->tianshou) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->tianshou) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.4.0->tianshou) (3.27.6)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.4.0->tianshou) (17.0.2)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.5.0->tianshou) (5.3.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.5.0->tianshou) (0.3.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.5.0->tianshou) (1.16.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.5.0->tianshou) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard>=2.5.0->tianshou) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard>=2.5.0->tianshou) (3.3.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard>=2.5.0->tianshou) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard>=2.5.0->tianshou) (2.0.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard>=2.5.0->tianshou) (2023.7.22)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard>=2.5.0->tianshou) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.4.0->tianshou) (1.3.0)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.5.0->tianshou) (0.5.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard>=2.5.0->tianshou) (3.2.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install gym==0.10.5\n",
        "!pip install pyglet==1.3.2\n",
        "!pip install tianshou"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HtuK2i1jQ4nc"
      },
      "outputs": [],
      "source": [
        "from make_env import make_env\n",
        "import numpy as np\n",
        "import copy\n",
        "from collections import deque, namedtuple\n",
        "import gym\n",
        "import random\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.nn.utils import clip_grad_norm_\n",
        "import matplotlib\n",
        "import matplotlib.animation as animation\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "from typing import Any, List, Optional, Tuple, Union\n",
        "from tianshou.data import Batch, ReplayBuffer, SegmentTree, to_numpy\n",
        "\n",
        "from JSAnimation.IPython_display import display_animation\n",
        "from IPython.display import HTML"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aAgBMa9uRaxk",
        "outputId": "d01bbd97-1086-4c08-9057-422a2a856e29"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n",
            "cuda:0\n"
          ]
        }
      ],
      "source": [
        "print(torch.cuda.device_count())\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wt7VMb_NxEoc"
      },
      "outputs": [],
      "source": [
        "class PrioritizedReplayBuffer(ReplayBuffer):\n",
        "    \"\"\"Implementation of Prioritized Experience Replay. arXiv:1511.05952.\n",
        "\n",
        "    :param float alpha: the prioritization exponent.\n",
        "    :param float beta: the importance sample soft coefficient.\n",
        "    :param bool weight_norm: whether to normalize returned weights with the maximum\n",
        "        weight value within the batch. Default to True.\n",
        "\n",
        "    .. seealso::\n",
        "\n",
        "        Please refer to :class:`~tianshou.data.ReplayBuffer` for other APIs' usage.\n",
        "    \"\"\"\n",
        "    def __init__(\n",
        "        self,\n",
        "        size: int,\n",
        "        alpha: float,\n",
        "        beta: float,\n",
        "        weight_norm: bool = True,\n",
        "        **kwargs: Any\n",
        "    ) -> None:\n",
        "        # will raise KeyError in PrioritizedVectorReplayBuffer\n",
        "        # super().__init__(size, **kwargs)\n",
        "        ReplayBuffer.__init__(self, size, **kwargs)\n",
        "        assert alpha > 0.0 and beta >= 0.0\n",
        "        self._alpha, self._beta = alpha, beta\n",
        "        self._max_prio = self._min_prio = 1.0\n",
        "        # save weight directly in this class instead of self._meta\n",
        "        self.weight = SegmentTree(size)\n",
        "        self.__eps = np.finfo(np.float32).eps.item()\n",
        "        self.options.update(alpha=alpha, beta=beta)\n",
        "        self._weight_norm = weight_norm\n",
        "\n",
        "    def init_weight(self, index: Union[int, np.ndarray]) -> None:\n",
        "        self.weight[index] = self._max_prio**self._alpha\n",
        "\n",
        "\n",
        "    def update(self, buffer: ReplayBuffer) -> np.ndarray:\n",
        "        indices = super().update(buffer)\n",
        "        self.init_weight(indices)\n",
        "        return indices\n",
        "\n",
        "\n",
        "    def add(\n",
        "        self,\n",
        "        batch: Batch,\n",
        "        buffer_ids: Optional[Union[np.ndarray, List[int]]] = None\n",
        "    ) -> Tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray]:\n",
        "        ptr, ep_rew, ep_len, ep_idx = super().add(batch, buffer_ids)\n",
        "        self.init_weight(ptr)\n",
        "        return ptr, ep_rew, ep_len, ep_idx\n",
        "\n",
        "\n",
        "    def sample_indices(self, batch_size: int) -> np.ndarray:\n",
        "        if batch_size > 0 and len(self) > 0:\n",
        "            scalar = np.random.rand(batch_size) * self.weight.reduce()\n",
        "            return self.weight.get_prefix_sum_idx(scalar)  # type: ignore\n",
        "        else:\n",
        "            return super().sample_indices(batch_size)\n",
        "\n",
        "\n",
        "    def get_weight(self, index: Union[int, np.ndarray]) -> Union[float, np.ndarray]:\n",
        "        \"\"\"Get the importance sampling weight.\n",
        "\n",
        "        The \"weight\" in the returned Batch is the weight on loss function to debias\n",
        "        the sampling process (some transition tuples are sampled more often so their\n",
        "        losses are weighted less).\n",
        "        \"\"\"\n",
        "        # important sampling weight calculation\n",
        "        # original formula: ((p_j/p_sum*N)**(-beta))/((p_min/p_sum*N)**(-beta))\n",
        "        # simplified formula: (p_j/p_min)**(-beta)\n",
        "        return (self.weight[index] / self._min_prio)**(-self._beta)\n",
        "\n",
        "\n",
        "    def update_weight(\n",
        "        self, index: np.ndarray, new_weight: Union[np.ndarray, torch.Tensor]\n",
        "    ) -> None:\n",
        "        \"\"\"Update priority weight by index in this buffer.\n",
        "\n",
        "        :param np.ndarray index: index you want to update weight.\n",
        "        :param np.ndarray new_weight: new priority weight you want to update.\n",
        "        \"\"\"\n",
        "        weight = np.abs(to_numpy(new_weight)) + self.__eps\n",
        "        self.weight[index] = weight**self._alpha\n",
        "        self._max_prio = max(self._max_prio, weight.max())\n",
        "        self._min_prio = min(self._min_prio, weight.min())\n",
        "\n",
        "\n",
        "    def __getitem__(self, index: Union[slice, int, List[int], np.ndarray]) -> Batch:\n",
        "        if isinstance(index, slice):  # change slice to np array\n",
        "            # buffer[:] will get all available data\n",
        "            indices = self.sample_indices(0) if index == slice(None) \\\n",
        "                else self._indices[:len(self)][index]\n",
        "        else:\n",
        "            indices = index  # type: ignore\n",
        "        batch = super().__getitem__(indices)\n",
        "        weight = self.get_weight(indices)\n",
        "        # ref: https://github.com/Kaixhin/Rainbow/blob/master/memory.py L154\n",
        "        batch.weight = weight / np.max(weight) if self._weight_norm else weight\n",
        "        return batch\n",
        "\n",
        "\n",
        "    def set_beta(self, beta: float) -> None:\n",
        "        self._beta = beta"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fbXAuTBjRfFj"
      },
      "outputs": [],
      "source": [
        "class PolicyNetwork(nn.Module):\n",
        "    def __init__(self,num_state,num_action,hidden_size=64,init_w=3e-3):\n",
        "        super(PolicyNetwork,self).__init__()\n",
        "        self.fc1 = nn.Linear(num_state,hidden_size)\n",
        "        self.fc2 = nn.Linear(hidden_size,hidden_size)\n",
        "        self.fc3 = nn.Linear(hidden_size,hidden_size)\n",
        "        self.fc4 = nn.Linear(hidden_size,num_action)\n",
        "        self.fc4.weight.data.uniform_(-init_w, init_w)\n",
        "        self.fc4.bias.data.uniform_(-init_w, init_w)\n",
        "\n",
        "    def forward(self,x):\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = F.relu(self.fc3(x))\n",
        "        action = self.fc4(x)\n",
        "        return action"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p6PO05WpRhOL"
      },
      "outputs": [],
      "source": [
        "class QNetwork(nn.Module):\n",
        "    def __init__(self,num_state,num_action,hidden_size=64,init_w=3e-3):\n",
        "        super(QNetwork,self).__init__()\n",
        "        self.fc1 = nn.Linear(num_state+num_action,hidden_size)\n",
        "        self.fc2 = nn.Linear(hidden_size,hidden_size)\n",
        "        self.fc3 = nn.Linear(hidden_size,hidden_size)\n",
        "        self.fc4 = nn.Linear(hidden_size,1)\n",
        "        self.fc4.weight.data.uniform_(-init_w, init_w)\n",
        "        self.fc4.bias.data.uniform_(-init_w, init_w)\n",
        "\n",
        "    def forward(self,state,action):\n",
        "        x = torch.cat((state, action), dim=-1)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = F.relu(self.fc3(x))\n",
        "        q = self.fc4(x)\n",
        "        return q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OYBUpkJ2RjME"
      },
      "outputs": [],
      "source": [
        "class OrnsteinUhlenbeckProcess:\n",
        "    def __init__(self, theta=0.15, mu=0.0, sigma=0.2, dt=1e-2, x0=None, size=1, sigma_min=None, n_steps_annealing=1000):\n",
        "        self.theta = theta\n",
        "        self.mu = mu\n",
        "        self.sigma = sigma\n",
        "        self.dt = dt\n",
        "        self.x0 = x0\n",
        "        self.size = size\n",
        "        self.num_steps = 0\n",
        "\n",
        "        self.x_prev = self.x0 if self.x0 is not None else np.zeros(self.size)\n",
        "\n",
        "        if sigma_min is not None:\n",
        "            self.m = -float(sigma - sigma_min) / float(n_steps_annealing)\n",
        "            self.c = sigma\n",
        "            self.sigma_min = sigma_min\n",
        "        else:\n",
        "            self.m = 0\n",
        "            self.c = sigma\n",
        "            self.sigma_min = sigma\n",
        "\n",
        "    def current_sigma(self):\n",
        "        sigma = max(self.sigma_min, self.m * float(self.num_steps) + self.c)\n",
        "        return sigma\n",
        "\n",
        "    def sample(self):\n",
        "        x = self.x_prev + self.theta * (self.mu - self.x_prev) * self.dt + self.current_sigma() * np.sqrt(self.dt) * np.random.normal(size=self.size)\n",
        "        self.x_prev = x\n",
        "        self.num_steps += 1\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vyrnipA7RlYT"
      },
      "outputs": [],
      "source": [
        "class Learner:\n",
        "    def __init__(self,observation_space,action_space, num_agent, gamma=0.95,lr=0.01,batch_size=1024,memory_size=int(1e6),tau=0.01,grad_norm_clipping = 0.5):\n",
        "        self.num_state = observation_space\n",
        "        self.num_action = action_space\n",
        "        self.gamma = gamma\n",
        "\n",
        "        self.actor = PolicyNetwork(self.num_state,self.num_action)\n",
        "        self.target_actor = copy.deepcopy(self.actor)\n",
        "        self.actor_optimizer = optim.Adam(self.actor.parameters(),lr=0.001)\n",
        "        self.critic = QNetwork(self.num_state,self.num_action)\n",
        "        self.target_critic = copy.deepcopy(self.critic)\n",
        "        self.critic_optimizer = optim.Adam(self.critic.parameters(),lr=lr)\n",
        "\n",
        "        # Wrap your models with DataParallel\n",
        "        if torch.cuda.device_count() > 1:\n",
        "          print(\"Using\", torch.cuda.device_count(), \"GPUs!\")\n",
        "          self.actor = torch.nn.DataParallel(self.actor)\n",
        "          self.target_actor = torch.nn.DataParallel(self.target_actor)\n",
        "          self.critic = torch.nn.DataParallel(self.critic)\n",
        "          self.target_critic = torch.nn.DataParallel(self.target_critic)\n",
        "        else:\n",
        "          self.actor = self.actor.to(device)\n",
        "          self.target_actor = self.target_actor.to(device)\n",
        "          self.critic = self.critic.to(device)\n",
        "          self.target_critic = self.target_critic.to(device)\n",
        "\n",
        "        self.pri_buffer = PrioritizedReplayBuffer(memory_size, alpha=0.6, beta=0.4)\n",
        "        self.loss_fn = torch.nn.MSELoss()\n",
        "        self.batch_size = batch_size\n",
        "        self.is_gpu = torch.cuda.is_available\n",
        "        self.noise = OrnsteinUhlenbeckProcess(size=self.num_action)\n",
        "        self.grad_norm_clipping = grad_norm_clipping\n",
        "        self.tau = tau\n",
        "        self.num_agent = num_agent\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def td_targeti(self,rewards,states,next_states,dones):\n",
        "        next_actions = torch.tanh(self.target_actor(states))\n",
        "        next_q = self.target_critic(next_states,next_actions)\n",
        "        td_targeti = rewards.unsqueeze(1) + self.gamma * next_q*(1.-dones.unsqueeze(1))\n",
        "        return td_targeti.float()\n",
        "\n",
        "    def update(self):\n",
        "      indices = self.pri_buffer.sample_indices(self.batch_size)\n",
        "      samples = self.pri_buffer.__getitem__(indices)\n",
        "      states, actions, rewards, next_states, dones = samples['obs'], samples['act'], samples['rew'], samples['obs_next'], samples['terminated']\n",
        "\n",
        "      states = torch.FloatTensor(states).to(device)\n",
        "      next_states = torch.FloatTensor(next_states).to(device)\n",
        "      actions = torch.FloatTensor(actions).to(device)\n",
        "      rewards = torch.FloatTensor(rewards).to(device)\n",
        "      dones = torch.IntTensor(np.array(dones)).to(device)\n",
        "\n",
        "      td_targeti = self.td_targeti(rewards,states,next_states,dones)\n",
        "      current_q = self.critic(states,actions)\n",
        "      critic_loss = self.loss_fn(current_q,td_targeti)\n",
        "      \"\"\" Update priorities based on TD errors \"\"\"\n",
        "      td_errors = (td_targeti - current_q).t()          # Calculate the TD Errors\n",
        "      self.pri_buffer.update_weight(indices, td_errors.data.detach().cpu().numpy())\n",
        "\n",
        "      self.critic_optimizer.zero_grad()\n",
        "      critic_loss.backward()\n",
        "      clip_grad_norm_(self.critic.parameters(),max_norm=self.grad_norm_clipping)\n",
        "      self.critic_optimizer.step()\n",
        "      ac_up = self.actor(states)\n",
        "      ac = torch.tanh(ac_up)\n",
        "      pr = -self.critic(states,ac).mean()\n",
        "      pg = (ac.pow(2)).mean()\n",
        "      actor_loss = pr + pg*1e-3\n",
        "      self.actor_optimizer.zero_grad()\n",
        "      clip_grad_norm_(self.actor.parameters(),max_norm=self.grad_norm_clipping)\n",
        "      actor_loss.backward()\n",
        "      self.actor_optimizer.step()\n",
        "\n",
        "      for target_param, param in zip(self.target_actor.parameters(), self.actor.parameters()):\n",
        "        target_param.data.copy_(self.tau * param.data + (1.0 - self.tau) * target_param.data)\n",
        "      for target_param, param in zip(self.target_critic.parameters(), self.critic.parameters()):\n",
        "        target_param.data.copy_(self.tau * param.data + (1.0 - self.tau) * target_param.data)\n",
        "\n",
        "    def inference(self,state,greedy=False):\n",
        "        state = torch.tensor(state,dtype=torch.float).cuda()\n",
        "        action = torch.tanh(self.actor(state))\n",
        "        if not greedy:\n",
        "            action += torch.tensor(self.noise.sample(),dtype=torch.float).cuda()\n",
        "        return np.clip(action.detach().cpu().numpy(),-1.0,1.0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZKQGvERZE0Bg"
      },
      "outputs": [],
      "source": [
        "class Actors:\n",
        "    def __init__(self, num_agent, learner):\n",
        "        self.num_agent = num_agent\n",
        "        self.learner = learner\n",
        "\n",
        "    def get_action(self,states, greedy=False):\n",
        "      actions = []\n",
        "      for i in range(num_agent):\n",
        "        action = self.learner.inference(states[i])\n",
        "        actions.append(action)\n",
        "      return actions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GajVdLbEIIPz"
      },
      "source": [
        "## Initialize parameters\n",
        "## Initialize memory buffer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3QrcPP-ERpND",
        "outputId": "c4cb61a3-cd9b-4293-91ec-93b45056c431"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n",
            "10 Data collected\n"
          ]
        }
      ],
      "source": [
        "# num_episode = 50000\n",
        "# memory_size = 100000\n",
        "# initial_memory_size = 100000\n",
        "\n",
        "num_episode = 50\n",
        "memory_size = 10\n",
        "initial_memory_size = 10\n",
        "episode_rewards = []\n",
        "num_average_epidodes = 100\n",
        "\n",
        "env = make_env('simple_spread')\n",
        "num_agent=env.n\n",
        "max_steps = 25\n",
        "observation_space = 18\n",
        "action_space = 5\n",
        "learner = Learner(observation_space, action_space, num_agent, memory_size)\n",
        "agents = Actors(num_agent, learner)\n",
        "\n",
        "# Initially, put the data into the replay buffer when an action with noise was taken\n",
        "states = env.reset()\n",
        "for step in range(initial_memory_size):\n",
        "    if step % max_steps == 0:\n",
        "        states = env.reset()\n",
        "    actions = agents.get_action(states)\n",
        "    next_states, rewards, dones, _ = env.step(actions)\n",
        "    for i in range(num_agent):\n",
        "      batch = Batch({'obs': states[i], 'act': actions[i], 'rew': rewards[i], 'obs_next': next_states[i], 'terminated': dones[i], 'truncated': dones[i]})\n",
        "      agents.learner.pri_buffer.add(batch)\n",
        "    states = next_states\n",
        "print('%d Data collected' % (initial_memory_size))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l7aV0pRFIRnj"
      },
      "source": [
        "## Train agent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C36bm_K6Rtf0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 489
        },
        "outputId": "8c897ba7-1373-4719-9ef7-165575fb01d0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 0 finished | Episode reward -651.632094\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "for episode in range(num_episode):\n",
        "    states = env.reset()\n",
        "    episode_reward = 0\n",
        "    for t in range(max_steps):\n",
        "        actions = agents.get_action(states)\n",
        "        next_states, rewards, dones, _ = env.step(actions)\n",
        "        episode_reward += sum(rewards)\n",
        "        for i in range(num_agent):\n",
        "          batch = Batch({'obs': states[i], 'act': actions[i], 'rew': rewards[i], 'obs_next': next_states[i], 'terminated': dones[i], 'truncated': dones[i]})\n",
        "          agents.learner.pri_buffer.add(batch)\n",
        "        states = next_states\n",
        "        if all(dones):\n",
        "            break\n",
        "    if episode % 5 == 0:\n",
        "        agents.learner.update()\n",
        "    episode_rewards.append(episode_reward)\n",
        "    if episode % 100 == 0:\n",
        "        print(\"Episode %d finished | Episode reward %f\" % (episode, episode_reward))\n",
        "\n",
        "# Compute the moving average of cumulative rewards\n",
        "moving_average = np.convolve(episode_rewards, np.ones(num_average_epidodes)/num_average_epidodes, mode='valid')\n",
        "plt.plot(np.arange(len(moving_average)),moving_average)\n",
        "plt.title('Average rewards in %d episodes' % num_average_epidodes)\n",
        "plt.xlabel('episode')\n",
        "plt.ylabel('rewards')\n",
        "plt.show()\n",
        "\n",
        "env.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8WeJmRE-IT30"
      },
      "source": [
        "## Test agent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_nYcbknFR2iM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1f5dbdf0-30ff-45df-8021-23ebc9d9a1ff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-753.7678919297822\n"
          ]
        }
      ],
      "source": [
        "states = env.reset()\n",
        "episode_reward = 0\n",
        "\n",
        "for t in range(max_steps):\n",
        "    actions = agents.get_action(states,greedy=True)\n",
        "    next_states, rewards, dones, _ = env.step(actions)\n",
        "    episode_reward += sum(rewards)\n",
        "\n",
        "    states = next_states\n",
        "print(episode_reward)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "gpuType": "A100"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}